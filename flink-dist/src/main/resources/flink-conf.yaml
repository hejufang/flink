################################################################################
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
# limitations under the License.
################################################################################

common:
  taskmanager.memory.preallocate: false
  parallelism.default: 1
  stream-partitioner.default: rescale
  
  state.backend: rocksdb
  state.backend.rocksdb.checkpoint.transfer.thread.num: 4
  state.backend.rocksdb.use-fsync: true
  state.checkpoints.dir: ${checkpoint.hdfs.prefix}/1.9/flink/fs_checkpoint_dir
  state.checkpoints.num-retained: 3

  taskmanager.network.memory.fraction: 0.3
  taskmanager.network.memory.max: 2147483648

  high-availability: zookeeper
  high-availability.storageDir: ${hdfs.prefix}/${clusterName}/1.9/ha/
  high-availability.zookeeper.path.root: /${dc}/${clusterName}/flink
  high-availability.zookeeper.client.max-retry-attempts: 20 # default 3
  high-availability.zookeeper.client.connection-timeout: 60000 # default 15000ms
  high-availability.zookeeper.client.retry-wait: 20000 # default 5000ms
  high-availability.zookeeper.client.session-timeout: 180000 # default 60000ms, be careful to change this.
  zookeeper.sasl.disable: true

  yarn.application-attempts: 5
  yarn.application-attempt-failures-validity-interval: 3600000
  yarn.conf.cluster_queue_name.enable: true
  yarn.env-include-flink-conf: true
  flink.jobmanager.yarn.config.yarn.client.failover-max-attempts: -1
  flink.jobmanager.yarn.config.yarn.resourcemanager.connect.retry-interval.ms: 1000
  flink.jobmanager.yarn.config.yarn.resourcemanager.connect.max-wait.ms: -1
  flink.client.yarn.config.yarn.client.failover-max-attempts: -1
  flink.client.yarn.config.yarn.resourcemanager.connect.retry-interval.ms: 1000
  flink.client.yarn.config.yarn.resourcemanager.connect.max-wait.ms: 900000

  job.work.dir: ${hdfs.prefix}/${clusterName}/1.9/

# fs.hdfs.hdfssite: /opt/tiger/yarn_deploy/hadoop/conf/hdfs-site.xml

  metrics.reporters: opentsdb_reporter,databus_reporter
  metrics.reporter.opentsdb_reporter.class: org.apache.flink.metrics.opentsdb.OpentsdbReporter
  metrics.reporter.opentsdb_reporter.interval: 20 SECONDS
  metrics.reporter.databus_reporter.class: org.apache.flink.metrics.databus.DatabusReporter
  metrics.reporter.databus_reporter.interval: 60 SECONDS

  prune.buffer.threshold: 262144

  jobmanager.archive.fs.dir: ${hdfs.prefix}/${clusterName}/1.9/completed-jobs
  historyserver.archive.fs.dir: ${hdfs.prefix}/${clusterName}/1.9/completed-jobs
  historyserver.web.tmpdir: /opt/tmp/flink/historyserver/tmpdir

  akka.ask.timeout: 180 s

  containerized.jobmanager.heap-cutoff-ratio: 0.1

  flink.lib.path: lib_new_conf


  restart-strategy: failure-rate
  restart-strategy.failure-rate.max-failures-per-interval: 100
  restart-strategy.failure-rate.failure-rate-interval: 40 min
  restart-strategy.failure-rate.delay: 20 s

# restart-strategy: fixed-delay
# restart-strategy.fixed-delay.attempts: 100
# restart-strategy.fixed-delay.delay: 20 s
# The failover strategy, i.e., how the job computation recovers from task failures.
# Only restart tasks that may have been affected by the task failure, which typically includes
# downstream tasks and potentially upstream tasks if their produced data is no longer available for consumption.

  jobmanager.execution.failover-strategy: region
  jobmanager.execution.region-failover.always-region-when-no-resource: true
  jobmanager.execution.status-dutation-ms: 30000

#==============================================================================
# Rest & web frontend
#==============================================================================

  dc: cn
  check.job.unique: true

  job.unique.zookeeper.client.session-timeout: 5000
  job.unique.zookeeper.client.connection-timeout: 10000

  taskmanager.network.credit-model: true
  yarn.per-job-cluster.include-user-jar: FIRST

  base_jar: deploy/flink-1.9/basejar/flink-python-byted.jar
  bin: deploy/flink-1.9/bin/flink
  vcores: 4
  ms_url: http://ms.byted.org
  ms_zone: CN
  HADOOP_CONF_DIR: /opt/tiger/yarn_deploy/hadoop-2.6.0-cdh5.4.4/conf/
  kafka_server_url: http://kafka-config.byted.org

  # Configurations for dashboard
  dashboard.data_source: bytetsd

  # Configurations for dtop
  dtop.data_source: dtop_cn
  dtop.database: dtop

  # Configurations for job meta db
  jobmeta.db.name: dayu

  # Configurations for smart resources
  smart-resources.service-name: data.inf.sr_estimater.service.lf
  log4j.appender.databus.channel: yarn_container_level_log

  # Configurations for docker mode
  runtime.lib.dir: /opt/tiger/flink_deploy/deploy/flink-1.9/lib
  runtime.conf.dir: /opt/tiger/flink_deploy/deploy/flink-1.9/conf

  docker.default_image: yarn_runtime_flink:latest
  docker.image.include_lib: false
  docker.authorization: "Basic Rmxpbms6Z2huZTZrcGdqM2RvMzcxNHF0djBrZWYxbnd3aHNra2Q="
  docker.version_template_url: http://%s/api/v1/images/self-make/latest_tag/?psm=%s&region_list=%s
  docker.server: image-manager.byted.org
  docker.hub: hub.byted.org
  docker.region: China-North-LF

  nmclientasync.enabled: true
  taskmanager.initial-on-start: false
  resourcemanager.taskmanager-timeout: 600000
  slot.request.timeout: 300000
  slot.idle.timeout: 900000

  # client configs
  rest.await-leader-timeout: 300000
  rest.retry.max-attempts: 30
  rest.retry.delay: 10000

  # Gang scheduler
  yarn.gang-scheduler.enable: false
  yarn.gang-scheduler.node-skip-high-load: 2.5
  yarn.gang-scheduler.container-decentralized-average-weight: 10
  yarn.gang-scheduler.node-quota-usage-average-weight: 1
  yarn.gang-scheduler.wait-time-before-fatal-ms: 300000
  yarn.gang-scheduler.wait-time-before-retry-ms: 1000
  yarn.gang-scheduler.max-retry-times: 5
  yarn.gang-scheduler.downgrade-timeout-ms: 1800000
  yarn.gang-scheduler.container-descheduler.enable: false
  yarn.gang-scheduler.container-descheduler.disk-type-enable: false
  yarn.provided.lib.dirs.enabled: false

  # GC log options
  flink.gc.log.opts: -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=100M
  flink.gc.g1: false
  yarn.taskmanager.set_token: false

  # subpartition type
  taskmanager.network.bounded-blocking-subpartition-type: file

  # blacklist
  blacklist.taskmanager.enabled: true
  blacklist.task.enabled: true
  blacklist.max-task-failure-num-per-host: 5
  blacklist.max-taskmanager-failure-num-per-host: 2
  blacklist.task-blacklist-max-length: 10
  blacklist.taskmanager-blacklist-max-length: 50
  blacklist.failure-timeout: "20 min"
  blacklist.check-interval: "1 min"

  jobmanager.upload-user-jar: false

  web.submit.enable: false
  resourcemanager.shuffle-pending-slots: false

  # The Netty send and receive buffer size.
  taskmanager.network.netty.sendReceiveBufferSize: 4194304

  taskmanager.number-extra-initial: 0
  taskmanager.extra-initial-fraction: 0

  # yarn slow container detection
  yarn.slow-container.enabled: true
  yarn.slow-container.timeout-ms: 120000
  yarn.slow-container.check-interval-ms: 10000
  yarn.slow-container.quantile: 0.9
  yarn.slow-container.threshold-factor: 1.5

  jobmanager.execution.schedule-task-fairly: false

  heartbeat.timeout: 180000
  heartbeat.interval: 40000

  grafana.domain_url: "https://grafana.byted.org"
  register-dashboard.token: "Bearer eyJrIjoiYjZMS0hPSXZybVpOOWJMS3pLRHkwaXRoWWI2RW1UT2oiLCJuIjoianN0b3JtIiwiaWQiOjF9"

  bytedance.streaming.yarn.gang-scheduler.enable: true
  bytedance.streaming.yarn.gang-scheduler.jobmanager.enable: true
  bytedance.streaming.yarn.gang-scheduler.container-descheduler.enable: false
  bytedance.streaming.yarn.gang-scheduler.container-descheduler.disk-type-enable: true
  bytedance.streaming.taskmanager.initial-on-start: true
  bytedance.streaming.taskmanager.number-initial-percentage: 1.0
  bytedance.streaming.flink.job_api: DataStream
  bytedance.streaming.jobmanager.execution.failover-strategy: "full"
  bytedance.streaming.jobmanager.execution.schedule-task-fairly: true
  bytedance.streaming.jobmanager.partition.release-during-job-execution: false
  bytedance.streaming.cluster.evenly-spread-out-slots: true

  # smart-resource
  taskmanager.network.memory.lazy-allocate: true

  # ipv6
  ipv6.enabled: false
  ipv6.supported.cluster: leser,quoka,quaga,hippo

  # hdfs conf for checkpoint
  flink.checkpoint.hdfs.dfs.datanode.socket.write.timeout: 30000
  flink.checkpoint.hdfs.dfs.client.socket-timeout: 30000
  flink.checkpoint.hdfs.ipc.client.ping: false
  flink.checkpoint.hdfs.ipc.ping.interval: 10000
  flink.checkpoint.hdfs.ipc.client.connect.max.retries.on.timeouts: 5
  flink.checkpoint.hdfs.ipc.client.connect.timeout: 2000
  flink.checkpoint.hdfs.ipc.client.connect.retry.interval: 500
  flink.checkpoint.hdfs.io.file.buffer.size: 1048576
  flink.checkpoint.hdfs.dfs.pipeline.fast-failover.bytes.threshold: 5242880
  flink.checkpoint.hdfs.dfs.pipeline.fast-failover.max.failover.times: 10

flink:
  dc: cn
  clusterName: flink
  high-availability.zookeeper.quorum: 10.17.58.36:2181,10.17.58.40:2181,10.17.58.44:2181,10.17.58.45:2181,10.17.58.78:2181
  hdfs.prefix: hdfs://haruna/flink_lf
  checkpoint.hdfs.prefix: hdfs://hdfsvip/home/byte_flink_checkpoint
  bytedance.streaming.yarn.gang-scheduler.container-descheduler.enable: true
  metrics.reporter.databus_reporter.warehouse.channel: flink_dw_metrics


dw:
  dc: cn
  clusterName: dw
  high-availability.zookeeper.quorum: 10.11.43.39:2184,10.11.43.66:2184,10.224.152.92:2184,10.224.71.64:2184,10.224.71.66:2184
  hdfs.prefix: hdfs://haruna/flink_lf
  checkpoint.hdfs.prefix: hdfs://hdfsvip/home/byte_flink_checkpoint
  bytedance.streaming.yarn.gang-scheduler.container-descheduler.enable: true
  metrics.reporter.databus_reporter.warehouse.channel: flink_dw_metrics

lepad:
  dc: cn
  clusterName: lepad
  high-availability.zookeeper.quorum: 10.8.32.25:2184,10.8.32.68:2184,10.8.32.74:2184,10.8.32.72:2184,10.8.39.142:2184
  hdfs.prefix: hdfs://haruna/flink_lf
  checkpoint.hdfs.prefix: hdfs://hdfsvip/home/byte_flink_checkpoint
  bytedance.streaming.yarn.gang-scheduler.container-descheduler.enable: true
  metrics.reporter.databus_reporter.warehouse.channel: flink_dw_metrics
  yarn.provided.lib.dirs.enabled: true

larva:
  dc: cn
  clusterName: larva
  flink.parallel.gc.thread.use.cores: true
  high-availability.zookeeper.quorum: 10.8.32.25:2184,10.8.32.68:2184,10.8.32.74:2184,10.8.32.72:2184,10.8.39.142:2184
  hdfs.prefix: hdfs://haruna/flink_lf
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

locst:
  dc: cn
  clusterName: locst
  high-availability.zookeeper.quorum: 10.224.193.108:2181,10.224.193.109:2181,10.224.193.93:2181,10.224.193.95:2181,10.224.193.96:2181
  hdfs.prefix: hdfs://haruna/flink_lf
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

oryx:
  dc: cn
  clusterName: oryx
  high-availability.zookeeper.quorum: 10.8.32.25:2184,10.8.32.68:2184,10.8.32.74:2184,10.8.32.72:2184,10.8.39.142:2184
  hdfs.prefix: hdfs://haruna/flink_lf
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

default:
  dc: cn
  clusterName: default
  high-availability.zookeeper.quorum: 10.8.32.25:2184,10.8.32.68:2184,10.8.32.74:2184,10.8.32.72:2184,10.8.39.142:2184
  hdfs.prefix: hdfs://haruna/flink_lf
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

leser:
  dc: cn
  clusterName: leser
  high-availability.zookeeper.quorum: 10.8.32.25:2184,10.8.32.68:2184,10.8.32.74:2184,10.8.32.72:2184,10.8.39.142:2184
  hdfs.prefix: hdfs://haruna/flink_lf
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  metrics.reporter.databus_reporter.warehouse.channel: flink_dw_metrics
  yarn.provided.lib.dirs.enabled: true

lobst:
  dc: cn
  clusterName: lobst
  high-availability.zookeeper.quorum: 10.8.32.25:2184,10.8.32.68:2184,10.8.32.74:2184,10.8.32.72:2184,10.8.39.142:2184
  hdfs.prefix: hdfs://haruna/flink_lf
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

wj:
  dc: cn
  clusterName: wj
  high-availability.zookeeper.quorum: 10.8.32.25:2184,10.8.32.68:2184,10.8.32.74:2184,10.8.32.72:2184,10.8.39.142:2184
  hdfs.prefix: hdfs://haruna/flink_hl
  checkpoint.hdfs.prefix: hdfs://haruna/flink_hl

hl:
  dc: cn
  clusterName: hl
  high-availability.zookeeper.quorum: 10.226.22.110:2181,10.226.22.38:2181,10.226.22.84:2181,10.226.22.85:2181,10.226.22.90:2181
  hdfs.prefix: hdfs://haruna/flink_hl
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

hyrax:
  dc: cn
  clusterName: hyrax
  high-availability.zookeeper.quorum: 10.23.72.70:2181,10.23.73.159:2181,10.23.73.222:2181,10.23.73.69:2181,10.23.73.81:2181
  hdfs.prefix: hdfs://haruna/flink_hl
  checkpoint.hdfs.prefix: hdfs://hdfsvip/home/byte_flink_checkpoint
  bytedance.streaming.yarn.gang-scheduler.container-descheduler.enable: true
  metrics.reporter.databus_reporter.warehouse.channel: flink_dw_metrics

horse:
  dc: cn
  clusterName: horse
  high-availability.zookeeper.quorum: 10.226.22.110:2181,10.226.22.38:2181,10.226.22.84:2181,10.226.22.85:2181,10.226.22.90:2181
  hdfs.prefix: hdfs://haruna/flink_hl
  checkpoint.hdfs.prefix: hdfs://hdfsvip/home/byte_flink_checkpoint
  bytedance.streaming.yarn.gang-scheduler.container-descheduler.enable: true
  metrics.reporter.databus_reporter.warehouse.channel: flink_dw_metrics
  yarn.provided.lib.dirs.enabled: true

hibis:
  dc: cn
  clusterName: hibis
  high-availability.zookeeper.quorum: 10.226.22.110:2181,10.226.22.38:2181,10.226.22.84:2181,10.226.22.85:2181,10.226.22.90:2181
  hdfs.prefix: hdfs://haruna/flink_hl
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

topi:
  dc: cn
  clusterName: topi
  high-availability.zookeeper.quorum: 10.226.22.110:2181,10.226.22.38:2181,10.226.22.84:2181,10.226.22.85:2181,10.226.22.90:2181
  hdfs.prefix: hdfs://haruna/flink_hl
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

hippo:
  dc: cn
  clusterName: hippo
  high-availability.zookeeper.quorum: 10.226.22.110:2181,10.226.22.38:2181,10.226.22.84:2181,10.226.22.85:2181,10.226.22.90:2181
  hdfs.prefix: hdfs://haruna/flink_hl
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

heron:
  dc: cn
  clusterName: heron
  high-availability.zookeeper.quorum: 10.226.22.110:2181,10.226.22.38:2181,10.226.22.84:2181,10.226.22.85:2181,10.226.22.90:2181
  hdfs.prefix: hdfs://haruna/flink_hl
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

hamer:
  dc: cn
  clusterName: hamer
  high-availability.zookeeper.quorum: 10.226.22.110:2181,10.226.22.38:2181,10.226.22.84:2181,10.226.22.85:2181,10.226.22.90:2181
  hdfs.prefix: hdfs://haruna/flink_hl
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

hyena:
  dc: cn
  clusterName: hyena
  high-availability.zookeeper.quorum: 10.226.22.110:2181,10.226.22.38:2181,10.226.22.84:2181,10.226.22.85:2181,10.226.22.90:2181
  hdfs.prefix: hdfs://haruna/flink_hl
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

hound:
  dc: cn
  clusterName: hound
  flink.parallel.gc.thread.use.cores: true
  high-availability.zookeeper.quorum: 10.226.22.110:2181,10.226.22.38:2181,10.226.22.84:2181,10.226.22.85:2181,10.226.22.90:2181
  hdfs.prefix: hdfs://haruna/flink_hl
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true

quail:
  dc: cn
  clusterName: quail
  high-availability.zookeeper.quorum: 10.129.16.103:2181,10.129.19.99:2181,10.129.36.17:2181,10.129.42.156:2181,10.129.42.93:2181
  hdfs.prefix: hdfs://haruna/flink_lq
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  yarn.provided.lib.dirs.enabled: true
  flink.parallel.gc.thread.use.cores: true

quoka:
  dc: cn
  clusterName: quoka
  high-availability.zookeeper.quorum: 10.129.16.103:2181,10.129.19.99:2181,10.129.36.17:2181,10.129.42.156:2181,10.129.42.93:2181
  hdfs.prefix: hdfs://haruna/flink_lq
  checkpoint.hdfs.prefix: hdfs://hdfsvip/home/byte_flink_checkpoint
  bytedance.streaming.yarn.gang-scheduler.container-descheduler.enable: true
  metrics.reporter.databus_reporter.warehouse.channel: flink_dw_metrics
  yarn.provided.lib.dirs.enabled: true
  flink.parallel.gc.thread.use.cores: true

quaga:
  dc: cn
  clusterName: quaga
  high-availability.zookeeper.quorum: 10.227.165.243:2181,10.227.165.222:2181,10.227.178.242:2181,10.227.174.244:2181,10.227.187.245:2181
  hdfs.prefix: hdfs://haruna/flink_lq
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  bytedance.streaming.yarn.gang-scheduler.container-descheduler.enable: true
  yarn.provided.lib.dirs.enabled: true
  flink.parallel.gc.thread.use.cores: true

quele:
  dc: cn
  clusterName: quele
  flink.parallel.gc.thread.use.cores: true
  high-availability.zookeeper.quorum: 10.227.165.243:2181,10.227.165.222:2181,10.227.178.242:2181,10.227.174.244:2181,10.227.187.245:2181
  hdfs.prefix: hdfs://haruna/flink_lq
  checkpoint.hdfs.prefix: hdfs://haruna/home/byte_flink_checkpoint
  bytedance.streaming.yarn.gang-scheduler.container-descheduler.enable: true
  yarn.provided.lib.dirs.enabled: true

camel:
  dc: cn
  clusterName: camel
  high-availability.zookeeper.quorum: 10.148.16.172:2181,10.148.16.37:2181,10.148.16.90:2181,10.148.20.100:2181,10.148.20.98:2181
  hdfs.prefix: hdfs://haruna/flink_cr
  checkpoint.hdfs.prefix: hdfs://haruna/flink_cr
  yarn.provided.lib.dirs.enabled: true

stork:
  dc: sg
  clusterName: stork
  high-availability.zookeeper.quorum: 10.105.4.10:2181,10.105.4.21:2181,10.105.4.35:2181,10.105.4.91:2181,10.105.4.254:2181
  hdfs.prefix: hdfs://harunasgee/flink_sgee
  checkpoint.hdfs.prefix: hdfs://harunasgee/flink_sgee
  dashboard.data_source: bytetsd_sgee
  dtop.data_source: dtop_alisg
  dtop.database: dtop_alisg
  smart-resources.service-name: data.inf.sr_estimater.service.alisg
  kafka_server_url: http://kafka-config-sg.byted.org
  log4j.appender.databus.channel: yarn_container_level_log_sg
  docker.server: image-manager.byted.org
  docker.hub: aliyun-sin-hub.byted.org
  docker.region: Aliyun_SG
  save-meta.enabled: false

shark:
  dc: sg
  clusterName: shark
  high-availability.zookeeper.quorum: 10.126.35.119:2181,10.126.35.162:2181,10.126.35.163:2181,10.126.35.186:2181,10.126.35.189:2181
  hdfs.prefix: hdfs://harunasglark/flink_sglark
  checkpoint.hdfs.prefix:  hdfs://harunasglark/flink_sglark
  dashboard.data_source: bytetsd_sgsaas1lark
  dtop.data_source: dtop_alisg
  dtop.database: dtop_alisg
  smart-resources.service-name: data.inf.sr_estimater.service.alisg
  kafka_server_url: http://kafka-config-sg.byted.org
  log4j.appender.databus.channel: yarn_container_level_log_sg
  docker.server: image-manager.byted.org
  docker.hub: aliyun-sin-hub.byted.org
  docker.region: Aliyun_SG
  save-meta.enabled: false

marmt:
  dc: va
  clusterName: marmt
  high-availability.zookeeper.quorum: 10.231.131.120:2181,10.231.131.100:2181,10.231.131.112:2181,10.231.131.124:2181,10.231.131.106:2181
  hdfs.prefix: hdfs://harunavaali/flink_maliva
  checkpoint.hdfs.prefix: hdfs://harunavaali/flink_maliva
  dashboard.data_source: bytetsd_gva
  dtop.data_source: dtop_maliva
  dtop.database: dtop_maliva
  smart-resources.service-name: data.inf.sr_estimater.service.maliva
  kafka_server_url: http://kafka-config-va.byted.org
  log4j.appender.databus.channel: yarn_container_level_log_mva_aliyun
  yaop_url: http://yaop-us.bytedance.net
  docker.server: image-manager.byted.org
  docker.hub: aliyun-va-hub.byted.org
  docker.region: Aliyun_VA
  jobmeta.db.name: flink_meta_va
  grafana.domain_url: "https://grafana-us.byted.org"
  metrics.reporter.databus_reporter.warehouse.channel: flink_dw_metrics_va
  checkpoint.client-checkpoint-verification-enable: true

macaw:
  dc: va
  clusterName: macaw
  high-availability.zookeeper.quorum: 10.231.131.120:2181,10.231.131.100:2181,10.231.131.112:2181,10.231.131.124:2181,10.231.131.106:2181
  hdfs.prefix: hdfs://harunavaali/flink_maliva
  checkpoint.hdfs.prefix: hdfs://harunavaali/flink_maliva
  dashboard.data_source: bytetsd_gva
  dtop.data_source: dtop_maliva
  dtop.database: dtop_maliva
  smart-resources.service-name: data.inf.sr_estimater.service.maliva
  kafka_server_url: http://kafka-config-va.byted.org
  log4j.appender.databus.channel: yarn_container_level_log_mva_aliyun
  yaop_url: http://yaop-us.bytedance.net
  docker.server: image-manager.byted.org
  docker.hub: aliyun-va-hub.byted.org
  docker.region: Aliyun_VA
  jobmeta.db.name: flink_meta_va
  grafana.domain_url: "https://grafana-us.byted.org"
  metrics.reporter.databus_reporter.warehouse.channel: flink_dw_metrics_va
  checkpoint.client-checkpoint-verification-enable: true
  yarn.provided.lib.dirs.enabled: true

grila:
  dc: i18n_gcp
  clusterName: grila
  high-availability.zookeeper.quorum: 10.99.53.218:2181,10.99.53.219:2181,10.99.53.220:2181,10.99.53.221:2181,10.99.53.222
  hdfs.prefix: hdfs://harunagcp/home/byte_compute_i18n_gcp
  checkpoint.hdfs.prefix: hdfs://harunagcp/home/byte_compute_i18n_gcp
  dashboard.data_source: bytetsd_useastred
  dtop.data_source: dtop_i18n
  dtop.database: dtop_i18n
  smart-resources.service-name: data.inf.sr_estimater.service.useast2a
  kafka_server_url: http://kafka-config-gcp.byted.org
  log4j.appender.databus.channel: yarn_container_level_log_mva_aliyun
  docker.server: image-manager.byted.org
  docker.hub: useast-red-hub.byted.org
  docker.region: US-East-Red
  yaop_url: http://yaop-gcp.bytedance.net
  jobmeta.db.name: flink_meta
  grafana.domain_url: "https://grafana-i18n.byted.org"
  register-dashboard.token: "Bearer eyJrIjoiSGlWUlRpQlZWcDhsdGJ4ZTRWcGtGc1VHcG8xT2h5UkkiLCJuIjoiZmxpbmsiLCJpZCI6MX0="

gavia:
  dc: i18n_gcp
  clusterName: gavia
  high-availability.zookeeper.quorum: 10.99.53.218:2181,10.99.53.219:2181,10.99.53.220:2181,10.99.53.221:2181,10.99.53.222
  hdfs.prefix: hdfs://harunagcp/home/byte_compute_i18n_gcp
  checkpoint.hdfs.prefix: hdfs://harunagcp/home/byte_compute_i18n_gcp
  dashboard.data_source: bytetsd_useastred
  dtop.data_source: dtop_i18n
  dtop.database: dtop_i18n
  smart-resources.service-name: data.inf.sr_estimater.service.useast2a
  kafka_server_url: http://kafka-config-gcp.byted.org
  log4j.appender.databus.channel: yarn_container_level_log_mva_aliyun
  docker.server: image-manager.byted.org
  docker.hub: useast-red-hub.byted.org
  docker.region: US-East-Red
  yaop_url: http://yaop-gcp.bytedance.net
  jobmeta.db.name: flink_meta
  grafana.domain_url: "https://grafana-i18n.byted.org"
  register-dashboard.token: "Bearer eyJrIjoiSGlWUlRpQlZWcDhsdGJ4ZTRWcGtGc1VHcG8xT2h5UkkiLCJuIjoiZmxpbmsiLCJpZCI6MX0="

alisg:
  dc: sg
  clusterName: alisg
  high-availability.zookeeper.quorum: 10.115.61.129:2181,10.115.61.130:2181,10.115.61.131:2181,10.115.61.132:2181,10.115.61.133:2181
  hdfs.prefix: hdfs://harunasg/flink_alisg
  checkpoint.hdfs.prefix: hdfs://harunasg/home/byte_flink_checkpoint_alisg
  dashboard.data_source: bytetsd_alisg
  dtop.data_source: dtop_alisg
  dtop.database: dtop_alisg
  smart-resources.service-name: data.inf.sr_estimater.service.alisg
  kafka_server_url: http://kafka-config-sg.byted.org
  log4j.appender.databus.channel: yarn_container_level_log_sg
  docker.server: 10.8.27.231:8002
  docker.hub: aliyun-sin-hub.byted.org
  docker.region: Aliyun_SG
  jobmeta.db.name: flink_meta_sg
  metrics.reporter.databus_reporter.warehouse.channel: flink_dw_metrics_sg
  checkpoint.client-checkpoint-verification-enable: true
  yarn.provided.lib.dirs.enabled: true

sloth:
  dc: sg
  clusterName: sloth
  high-availability.zookeeper.quorum: 10.245.24.23:2181,10.245.30.27:2181,10.245.30.47:2181,10.245.9.27:2181,10.245.9.34:2181
  hdfs.prefix: hdfs://harunasg/flink_sg_sg1
  checkpoint.hdfs.prefix: hdfs://harunasg/home/byte_flink_checkpoint_alisg
  dashboard.data_source: bytetsd_alisg
  dtop.data_source: dtop_alisg
  dtop.database: dtop_alisg
  smart-resources.service-name: data.inf.sr_estimater.service.alisg
  kafka_server_url: http://kafka-config-sg.byted.org
  log4j.appender.databus.channel: yarn_container_level_log_sg
  docker.server: image-manager.byted.org
  docker.hub: aliyun-sin-hub.byted.org
  docker.region: Aliyun_SG
  jobmeta.db.name: flink_meta_sg
  metrics.reporter.databus_reporter.warehouse.channel: flink_dw_metrics_sg
  checkpoint.client-checkpoint-verification-enable: true

boe:
  dc: vm
  clusterName: boe
  high-availability.zookeeper.quorum: 10.225.33.2:2181,10.225.28.3:2181,10.225.33.6:2181,10.225.125.22:2181,10.225.125.29:2181
  hdfs.prefix: hdfs://westeros/flink_boe
  checkpoint.hdfs.prefix: hdfs://westeros/flink_boe
  dashboard.data_source: bytetsd_boe
  kafka_server_url: http://kafka-config.byted.org
  log4j.appender.databus.channel: yarn_container_level_log_boe
  yaop_url: https://yaop-boe.bytedance.net
  yaop_token: 0ed7ea2fce8d4801a9d79adde7a91211
  save-meta.enabled: false
  grafana.domain_url: "http://grafana-boe.byted.org"
  register-dashboard.token: "Bearer eyJrIjoiTURSV01QeWNDZXJXYUNBdEhkSU94U2tKajU2M1BVM24iLCJuIjoiZmxpbmsiLCJpZCI6MX0="

cof:
  dc: vm
  clusterName: cof
  high-availability.zookeeper.quorum: 10.225.125.22:2181,10.225.125.29:2181,10.225.28.3:2181,10.225.33.2:2181,10.225.33.6:2181
  hdfs.prefix: hdfs://westeros/flink_cof
  checkpoint.hdfs.prefix: hdfs://westeros/flink_cof
  dashboard.data_source: bytetsd_cof
  kafka_server_url: http://kafka-config.byted.org
  log4j.appender.databus.channel: yarn_container_level_log
  yaop_url: https://yaop-boe.bytedance.net
  yaop_token: 0ed7ea2fce8d4801a9d79adde7a91211
  save-meta.enabled: false

swan:
  dc: ka
  clusterName: swan
  high-availability.zookeeper.quorum: 10.230.2.2:2181,10.230.2.10:2181,10.230.2.7:2181
  hdfs.prefix: hdfs://nestbackend/flink_swan
  checkpoint.hdfs.prefix: hdfs://nestbackend/flink_swan

koala:
  dc: ka2
  clusterName: koala
  high-availability.zookeeper.quorum: 10.230.9.118:2181,10.230.9.121:2181,10.230.9.102:2181
  hdfs.prefix: hdfs://nestbackend/flink_swan
  checkpoint.hdfs.prefix: hdfs://nestbackend/flink_swan

boei18n:
  dc: vm
  clusterName: boei18n
  high-availability.zookeeper.quorum: 10.231.8.12:2181,10.231.8.51:2181,10.231.8.25:2181,10.231.8.21:2181,10.231.8.29:2181
  hdfs.prefix: hdfs://essos/flink_boei18n
  checkpoint.hdfs.prefix: hdfs://essos/flink_boei18n
  dashboard.data_source: bytetsd_boei18n
  kafka_server_url: http://kafka-config.byted.org
  log4j.appender.databus.channel: yarn_container_level_log_boei18n
  # TODO(zhangguanghui): Waiting for Yaop to replace it with a domain url
  yaop_url: http://10.231.17.57:8092
  yaop_token: 0ed7ea2fce8d4801a9d79adde7a91211
  docker.hub: aliyun-va-hub.byted.org
  docker.namespace: yarn
  docker.region: Aliyun_VA
  save-meta.enabled: false
  grafana.domain_url: "http://grafana-boei18n.byted.org"
  register-dashboard.token: "Bearer eyJrIjoicndEUGRnNHpUZE9Gcm04VE5QSDdDV3JzbG8wWFZYa3IiLCJuIjoiZmxpbmsiLCJpZCI6MX0="
