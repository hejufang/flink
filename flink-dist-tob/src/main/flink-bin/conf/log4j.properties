################################################################################
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
# limitations under the License.
################################################################################

# This affects logging for both user code and Flink
shutdownHook                        = disable
rootLogger.level                    = INFO
rootLogger.appenderRefs             = console,file,rolling
rootLogger.appenderRef.console.ref  = ConsoleAppender
rootLogger.appenderRef.file.ref     = MainAppender
rootLogger.appenderRef.rolling.ref  = ByteRollingFile

# The following lines keep the log level of common libraries/connectors on
# log level INFO. The root logger does not override this. You have to manually
# change the log levels here.
logger.akka.name                    = akka
logger.akka.level                   = INFO
logger.kafka.name                   = org.apache.kafka
logger.kafka.level                  = INFO
logger.hadoop.name                  = org.apache.hadoop
logger.hadoop.level                 = INFO
logger.zookeeper.name               = org.apache.zookeeper
logger.zookeeper.level              = INFO

# standard log info
appender.console.name               = ConsoleAppender
appender.console.type               = CONSOLE
appender.console.layout.type        = PatternLayout
appender.console.layout.pattern     = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c - %m%n

# Log all infos in the given file
appender.main.name                  = MainAppender
appender.main.type                  = RollingFile
appender.main.append                = false
appender.main.fileName              = ${sys:log.file}
appender.main.filePattern           = ${sys:log.file}.%i
appender.main.layout.type           = PatternLayout
appender.main.layout.pattern        = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %-60t %x - %m%n
appender.main.policies.type         = Policies
appender.main.policies.size.type    = SizeBasedTriggeringPolicy
appender.main.policies.size.size    = 100MB
appender.main.strategy.type         = DefaultRolloverStrategy
appender.main.strategy.max          = 5

# Suppress the irrelevant (wrong) warnings from the Netty channel handler
logger.netty.name                   = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline
logger.netty.level                  = OFF

#tos appender
logger.rolling.name                 = com.bytedance
logger.rolling.level                = INFO
appender.rolling.type               = ByteRollingFile
appender.rolling.name               = ByteRollingFile
appender.rolling.fileName           = log/byteLog.log
appender.rolling.filePattern        = log/byteLog-%d{yyyy-MM-dd}-%i.log
appender.rolling.layout.type        = PatternLayout
appender.rolling.layout.pattern     = [%d{yyyy-MM-dd HH:mm:ss:SSS}] [%p] - %l - %m%n
appender.rolling.policies.type      = Policies
appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
appender.rolling.strategy.type      = DefaultRolloverStrategy
#
appender.rolling.policies.size.size = 10MB
appender.rolling.strategy.max       = 10

#
property.regionId                   = ${env:LOG.TOS.REGION_ID}
property.bucket                     = ${env:LOG.TOS.BUCKET}
property.filePathTemplate           = flink/${env:INSTANCE_ID}/${env:WORKSPACE_ID}/${env:CLUSTER_ID}/logs/${env:SUBMIT_ID}/running/${env:LOG.ROLE}-${env:_FLINK_POD_NAME}/log
property.tosEndpoint                = ${env:LOG.TOS.ENDPOINT}
property.accessKeyId                = ${env:LOG.TOS.AK}
property.accessKeySecret            = ${env:LOG.TOS.SK}
